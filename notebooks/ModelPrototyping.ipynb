{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "45.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load the full MNIST dataset\n",
    "full_dataset = MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "\n",
    "# Create a subset with the first 1000 samples\n",
    "subset_indices = range(500)\n",
    "subset_dataset = Subset(full_dataset, subset_indices)\n",
    "\n",
    "# Create a DataLoader for the subset\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Now you can use subset_dataloader to iterate over the subset of 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64]) tensor([2, 3, 3, 0, 6, 0, 9, 1, 6, 2, 8, 9, 2, 2, 3, 6, 5, 3, 6, 1, 1, 4, 2, 9,\n",
      "        5, 4, 2, 0, 6, 2, 1, 7, 9, 1, 9, 5, 1, 8, 4, 8, 9, 9, 6, 5, 9, 1, 4, 8,\n",
      "        9, 9, 1, 1, 3, 3, 9, 0, 8, 5, 3, 4, 0, 0, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "for data, label in dataloader:\n",
    "    print(data.shape, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total quantity of the dataset # 500 \n",
      "The shape of the data # torch.Size([52, 1, 64, 64]) \n"
     ]
    }
   ],
   "source": [
    "# Check the quantity of the dataset\n",
    "total_data = 0\n",
    "\n",
    "for image, label in dataloader:\n",
    "    total_data += image.shape[0]\n",
    "\n",
    "print(\"total quantity of the dataset # {} \".format(total_data))\n",
    "print(\"The shape of the data # {} \".format(image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual block for the Generator network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(x)\n",
    "        Performs a forward pass through the residual block.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    # Create a residual block\n",
    "    residual_block = ResidualBlock(in_channels=64)\n",
    "\n",
    "    # Perform forward pass\n",
    "    output = residual_block(input_tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the residual block.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output tensor after the residual block.\n",
    "        \"\"\"\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    \"\"\"\n",
    "    An up-sampling module for the Generator network.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(x)\n",
    "        Performs a forward pass through the up-sampling module.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    # Create an up-sampling module\n",
    "    upsample_module = UpSample()\n",
    "\n",
    "    # Perform forward pass\n",
    "    output = upsample_module(input_tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.PixelShuffle(upscale_factor=2),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the up-sampling module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output tensor after up-sampling.\n",
    "        \"\"\"\n",
    "        return self.upsample(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    The Generator network for image super-resolution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int, optional\n",
    "        Number of input channels. Default is 1.\n",
    "    num_residual_blocks : int, optional\n",
    "        Number of residual blocks in the network. Default is 16.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(x)\n",
    "        Performs a forward pass through the generator network.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    # Create a generator\n",
    "    generator = Generator(in_channels=1, num_residual_blocks=16)\n",
    "\n",
    "    # Perform forward pass\n",
    "    output_image = generator(input_image)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1, num_residual_blocks=16):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial Convolutional Layer\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), nn.PReLU()\n",
    "        )\n",
    "\n",
    "        # Residual Blocks\n",
    "        self.residuals = nn.Sequential(\n",
    "            *[ResidualBlock(64) for _ in range(num_residual_blocks)]\n",
    "        )\n",
    "\n",
    "        # Up-Sampling Module\n",
    "        self.upsample = nn.Sequential(*[UpSample() for _ in range(2)])\n",
    "\n",
    "        # Final Convolutional Layer\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, in_channels, kernel_size=9, stride=1, padding=4), nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the generator network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input image tensor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output tensor after super-resolution.\n",
    "        \"\"\"\n",
    "        initial = self.initial(x)\n",
    "        residuals = self.residuals(initial)\n",
    "        x = initial + residuals\n",
    "        x = self.upsample(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of trainable parameters # 1491668\n"
     ]
    }
   ],
   "source": [
    "# Find out the total trainable parameters\n",
    "total_params = 0\n",
    "for params in generator.parameters():\n",
    "    total_params+=params.numel()\n",
    "    \n",
    "print(\"Total # of trainable parameters # {}\".format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it works or not\n",
    "noise_data = torch.randn(64, 1, 64, 64)\n",
    "generator(noise_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.nf = 64\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.nf, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf, self.nf, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.nf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf, self.nf * 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 2, self.nf * 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 2, self.nf * 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 4, self.nf * 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 4, self.nf * 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 8, self.nf * 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(self.nf * 8, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return torch.sigmoid(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    discriminator = Discriminator()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_data = torch.randn(64, 1, 64, 64)\n",
    "discriminator(noise_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params # 5214273 \n"
     ]
    }
   ],
   "source": [
    "# Total trainable params\n",
    "total_params = 0\n",
    "for params in discriminator.parameters():\n",
    "    total_params+=params.numel()\n",
    "    \n",
    "print(\"Total trainable params # {} \".format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr = 0.0002, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 1/8] [D loss: 0.6701189279556274] [G loss: 0.7624028325080872]\n",
      "[Epoch 0/10] [Batch 2/8] [D loss: 0.6509981155395508] [G loss: 0.757958710193634]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    D_loss = list()\n",
    "    G_loss = list()\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(imgs.size(0), 1, requires_grad=False)\n",
    "        fake = torch.zeros(imgs.size(0), 1, requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        optimizer_generator.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(imgs)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = loss_function(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_discriminator.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = loss_function(discriminator(real_imgs), valid)\n",
    "        fake_loss = loss_function(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_discriminator.step()\n",
    "        \n",
    "        G_loss.append(g_loss.item())\n",
    "        D_loss.append(d_loss.item())\n",
    "\n",
    "        if i%400:\n",
    "            print(\n",
    "                f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\"\n",
    "            )\n",
    "    \n",
    "    print(\"G_loss: {} - D_loss: {} \".format(np.array(G_loss).mean(), np.array(D_loss).mean()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
