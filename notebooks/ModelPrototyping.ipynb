{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load the full MNIST dataset\n",
    "full_dataset = MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "\n",
    "# Create a subset with the first 1000 samples\n",
    "subset_indices = range(500)\n",
    "subset_dataset = Subset(full_dataset, subset_indices)\n",
    "\n",
    "# Create a DataLoader for the subset\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(subset_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Now you can use subset_dataloader to iterate over the subset of 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64]) tensor([1, 2, 3, 0, 1, 4, 8, 0, 5, 2, 4, 5, 6, 1, 4, 6, 7, 7, 0, 1, 8, 5, 9, 8,\n",
      "        5, 7, 0, 2, 2, 0, 1, 0, 1, 3, 4, 3, 2, 3, 6, 8, 0, 4, 2, 1, 3, 8, 2, 1,\n",
      "        9, 3, 0, 5, 7, 9, 3, 9, 1, 0, 9, 5, 6, 6, 7, 6])\n"
     ]
    }
   ],
   "source": [
    "for data, label in dataloader:\n",
    "    print(data.shape, label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total quantity of the dataset # 500 \n",
      "The shape of the data # torch.Size([52, 1, 64, 64]) \n"
     ]
    }
   ],
   "source": [
    "# Check the quantity of the dataset\n",
    "total_data = 0\n",
    "\n",
    "for image, label in dataloader:\n",
    "    total_data += image.shape[0]\n",
    "\n",
    "print(\"total quantity of the dataset # {} \".format(total_data))\n",
    "print(\"The shape of the data # {} \".format(image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_residual_blocks=16):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), nn.PReLU()\n",
    "        )\n",
    "\n",
    "        self.residuals = nn.Sequential(\n",
    "            *[ResidualBlock(64) for _ in range(num_residual_blocks)]\n",
    "        )\n",
    "\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.PixelShuffle(upscale_factor=2),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(64, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.PixelShuffle(upscale_factor=2),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(64, in_channels, kernel_size=9, stride=1, padding=4), nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        residuals = self.residuals(initial)\n",
    "        x = initial + residuals\n",
    "        x = self.upsample(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of trainable parameters # 1491668\n"
     ]
    }
   ],
   "source": [
    "# Find out the total trainable parameters\n",
    "total_params = 0\n",
    "for params in generator.parameters():\n",
    "    total_params+=params.numel()\n",
    "    \n",
    "print(\"Total # of trainable parameters # {}\".format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it works or not\n",
    "noise_data = torch.randn(64, 1, 64, 64)\n",
    "generator(noise_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.nf = 64\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.nf, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf, self.nf, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.nf),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf, self.nf * 2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 2, self.nf * 2, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 2, self.nf * 4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 4, self.nf * 4, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 4, self.nf * 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(self.nf * 8, self.nf * 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(self.nf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(self.nf * 8, 1024, kernel_size=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(1024, 1, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return torch.sigmoid(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    discriminator = Discriminator()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_data = torch.randn(64, 1, 64, 64)\n",
    "discriminator(noise_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params # 5214273 \n"
     ]
    }
   ],
   "source": [
    "# Total trainable params\n",
    "total_params = 0\n",
    "for params in discriminator.parameters():\n",
    "    total_params+=params.numel()\n",
    "    \n",
    "print(\"Total trainable params # {} \".format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr = 0.0002, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 1/8] [D loss: 0.6755176782608032] [G loss: 0.6713829040527344]\n",
      "[Epoch 0/10] [Batch 2/8] [D loss: 0.6501513123512268] [G loss: 0.7601485848426819]\n",
      "[Epoch 0/10] [Batch 3/8] [D loss: 0.6265161037445068] [G loss: 0.7938126921653748]\n",
      "[Epoch 0/10] [Batch 4/8] [D loss: 0.5980849862098694] [G loss: 0.7848340272903442]\n",
      "[Epoch 0/10] [Batch 5/8] [D loss: 0.5757236480712891] [G loss: 0.8298689723014832]\n",
      "[Epoch 0/10] [Batch 6/8] [D loss: 0.5494447946548462] [G loss: 0.8864858150482178]\n",
      "[Epoch 0/10] [Batch 7/8] [D loss: 0.5144287943840027] [G loss: 0.9198465943336487]\n",
      "G_loss: 0.7973206043243408 - D_loss: 0.6106206402182579 \n",
      "[Epoch 1/10] [Batch 1/8] [D loss: 0.456842303276062] [G loss: 1.0538866519927979]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    D_loss = list()\n",
    "    G_loss = list()\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(imgs.size(0), 1, requires_grad=False)\n",
    "        fake = torch.zeros(imgs.size(0), 1, requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = imgs\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "        optimizer_generator.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(imgs)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = loss_function(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_discriminator.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = loss_function(discriminator(real_imgs), valid)\n",
    "        fake_loss = loss_function(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_discriminator.step()\n",
    "        \n",
    "        G_loss.append(g_loss.item())\n",
    "        D_loss.append(d_loss.item())\n",
    "\n",
    "        if i%400:\n",
    "            print(\n",
    "                f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\"\n",
    "            )\n",
    "    \n",
    "    print(\"G_loss: {} - D_loss: {} \".format(np.array(G_loss).mean(), np.array(D_loss).mean()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
