{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = MNIST(\".\", train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total quantity of the dataset # 60000 \n",
      "The shape of the data # torch.Size([32, 1, 64, 64]) \n"
     ]
    }
   ],
   "source": [
    "# Check the quantity of the dataset\n",
    "total_data = 0\n",
    "\n",
    "for image, label in dataloader:\n",
    "    total_data += image.shape[0]\n",
    "\n",
    "print(\"total quantity of the dataset # {} \".format(total_data))\n",
    "print(\"The shape of the data # {} \".format(image.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResidualBlock module used in deep neural networks to enable training of deeper networks.\n",
    "    Consists of two sets of Convolution, BatchNorm, and PReLU layers. The input is added to the output\n",
    "    of these layers, creating a residual connection.\n",
    "\n",
    "    Parameters:\n",
    "        in_channels (int): The number of channels in the input feature map.\n",
    "\n",
    "    Forward pass:\n",
    "        Accepts a 4D Tensor as input and returns a 4D Tensor with the same dimensions.\n",
    "        Applies the residual block operations and adds the input to the output of these operations.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels = 64):\n",
    "        self.in_channels = in_channels\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.in_channels, out_channels=self.in_channels, kernel_size=3, stride=1,padding=1,),\n",
    "            nn.BatchNorm2d(num_features=self.in_channels),\n",
    "            nn.PReLU(),\n",
    "            \n",
    "            nn.Conv2d(\n",
    "                in_channels = self.in_channels, out_channels=self.in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=in_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    \"\"\"\n",
    "    An UpSample module to upscale an image by a factor of 2 using PixelShuffle.\n",
    "    Uses a Conv2D layer to increase the number of channels followed by PixelShuffle\n",
    "    to upscale the image and a PReLU activation.\n",
    "\n",
    "    Forward pass:\n",
    "        Accepts a 4D Tensor as input and returns a 4D Tensor with the spatial dimensions\n",
    "        increased by a factor of 2 and the channels reduced by a factor of 4.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(UpSample, self).__init__()\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1\n",
    "            ),\n",
    "            nn.PixelShuffle(upscale_factor=2),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upsample(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator module of a Generative Adversarial Network (GAN) designed for tasks like image super-resolution.\n",
    "    It consists of an initial convolution, a series of ResidualBlocks, followed by Upsampling blocks,\n",
    "    and a final convolutional layer.\n",
    "\n",
    "    Parameters:\n",
    "        in_channels (int): The number of channels in the input images.\n",
    "        num_residual_blocks (int): The number of ResidualBlocks in the network.\n",
    "\n",
    "    Forward pass:\n",
    "        Accepts a 4D Tensor as input and passes it through the initial layer, a series of ResidualBlocks,\n",
    "        upsampling blocks, and a final convolutional layer to produce a 4D Tensor as output.\n",
    "        The output tensor has the same number of channels as the input and increased spatial dimensions.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, num_residual_blocks=16):\n",
    "        self.in_channels = in_channels\n",
    "        self.num_residual_block = num_residual_blocks\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = self.in_channels, out_channels=64, kernel_size=9, stride=1, padding=4),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        self.residuals = nn.Sequential(\n",
    "            *[ResidualBlock(64) for _ in range(num_residual_blocks)]\n",
    "        )\n",
    "\n",
    "        self.upsample = nn.Sequential(*[UpSample() for _ in range(2)])\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=in_channels, kernel_size=9, stride=1, padding=4), nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        residuals = self.residuals(initial)\n",
    "        x = initial + residuals\n",
    "        x = self.upsample(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of trainable parameters # 1491668\n"
     ]
    }
   ],
   "source": [
    "# Find out the total trainable parameters\n",
    "total_params = 0\n",
    "for params in generator.parameters():\n",
    "    total_params+=params.numel()\n",
    "    \n",
    "print(\"Total # of trainable parameters # {}\".format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 256, 256])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check it works or not\n",
    "noise_data = torch.randn(64, 1, 64, 64)\n",
    "generator(noise_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Discriminator module of a Generative Adversarial Network (GAN) used for discriminating between real and generated images.\n",
    "    The architecture consists of a series of convolutional layers with varying kernel sizes and strides,\n",
    "    followed by Batch Normalization and LeakyReLU activation. The network ends with an Adaptive Average Pooling layer\n",
    "    and two convolutional layers reducing the output to a single scalar value representing the probability\n",
    "    that the input image is real.\n",
    "\n",
    "    Parameters:\n",
    "        in_channels (int): The number of channels in the input images.\n",
    "\n",
    "    The architecture is dynamic and can be configured through the layers_config attribute,\n",
    "    which defines the structure of convolutional layers in the network.\n",
    "\n",
    "    Forward pass:\n",
    "        Accepts a 4D Tensor as input and passes it through a series of convolutional,\n",
    "        Batch Normalization, and LeakyReLU layers. The output is then passed through an Adaptive Average Pooling layer\n",
    "        and two more convolutional layers to produce a single scalar value as output,\n",
    "        representing the probability that the input image is real.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1):\n",
    "        self.in_channels = in_channels\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.nf = 64\n",
    "\n",
    "        self.layers_config = [\n",
    "            (self.in_channels, self.nf, 3, 1, 1, 0.2),\n",
    "            (self.nf, self.nf, 3, 2, 1, 0.2),\n",
    "            (self.nf, self.nf * 2, 3, 1, 1, 0.2),\n",
    "            (self.nf * 2, self.nf * 2, 3, 2, 1, 0.2),\n",
    "            (self.nf * 2, self.nf * 4, 3, 1, 1, 0.2),\n",
    "            (self.nf * 4, self.nf * 4, 3, 2, 1, 0.2),\n",
    "            (self.nf * 4, self.nf * 8, 3, 1, 1, 0.2),\n",
    "            (self.nf * 8, self.nf * 8, 3, 2, 1, 0.2),\n",
    "            \n",
    "        ]\n",
    "        self.model = self.connected_layer(layers_config=self.layers_config)\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels=self.nf * 8, out_channels=1024, kernel_size=1),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def connected_layer(self, layers_config):\n",
    "        layers = OrderedDict()\n",
    "        if layers_config:\n",
    "            for index, (\n",
    "                in_channels, out_channels, kernel_size, stride, padding, negative_slope) in enumerate(layers_config):\n",
    "                layers[\"{}_conv\".format(index)] = nn.Conv2d(in_channels = in_channels,\n",
    "                                                            out_channels = out_channels,\n",
    "                                                            kernel_size = kernel_size,\n",
    "                                                            stride = stride, padding = padding)\n",
    "                layers[\"{}_batch_norms\".format(index)] = nn.BatchNorm2d(\n",
    "                    num_features = out_channels)\n",
    "                layers[\"{}_activation\".format(index)] = nn.LeakyReLU(\n",
    "                    negative_slope = negative_slope, inplace = True)\n",
    "\n",
    "            return nn.Sequential(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.main(x)\n",
    "        return x.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    discriminator = Discriminator()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_data = torch.randn(64, 1, 64, 64)\n",
    "discriminator(noise_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params # 5214401 \n"
     ]
    }
   ],
   "source": [
    "# Total trainable params\n",
    "total_params = 0\n",
    "for params in discriminator.parameters():\n",
    "    total_params+=params.numel()\n",
    "    \n",
    "print(\"Total trainable params # {} \".format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
